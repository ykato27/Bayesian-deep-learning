{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a00d98",
   "metadata": {},
   "source": [
    "## How to use custom data and implement custom models and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330da4d4",
   "metadata": {},
   "source": [
    "### Building a simple, first model\n",
    "For demonstration purposes we will choose a simple fully connected model. It takes a timeseries of size input_size as input and outputs a new timeseries of size output_size. You can think of this input_size encoding steps and output_size decoding/prediction steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ada9613",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177c82ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9bfd196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class FullyConnectedModule(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size: int, output_size: int, hidden_size: int, n_hidden_layers: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # input layer\n",
    "        module_list = [nn.Linear(input_size, hidden_size), nn.ReLU()]\n",
    "        # hidden layers\n",
    "        for _ in range(n_hidden_layers):\n",
    "            module_list.extend([nn.Linear(hidden_size, hidden_size), nn.ReLU()])\n",
    "        # output layer\n",
    "        module_list.append(nn.Linear(hidden_size, output_size))\n",
    "\n",
    "        self.sequential = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x of shape: batch_size x n_timesteps_in\n",
    "        # output of shape batch_size x n_timesteps_out\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "# test that network works as intended\n",
    "network = FullyConnectedModule(\n",
    "    input_size=5, output_size=2, hidden_size=10, n_hidden_layers=2\n",
    ")\n",
    "x = torch.rand(20, 5)\n",
    "network(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5026b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from pytorch_forecasting.models import BaseModel\n",
    "\n",
    "\n",
    "class FullyConnectedModel(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        hidden_size: int,\n",
    "        n_hidden_layers: int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "        self.network = FullyConnectedModule(\n",
    "            input_size=self.hparams.input_size,\n",
    "            output_size=self.hparams.output_size,\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            n_hidden_layers=self.hparams.n_hidden_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        network_input = x[\"encoder_cont\"].squeeze(-1)\n",
    "        prediction = self.network(network_input)\n",
    "\n",
    "        # rescale predictions into target space\n",
    "        prediction = self.transform_output(prediction, target_scale=x[\"target_scale\"])\n",
    "\n",
    "        # We need to return a dictionary that at least contains the prediction\n",
    "        # The parameter can be directly forwarded from the input.\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c3f0a8",
   "metadata": {},
   "source": [
    "This is a very basic implementation that could be readily used for training. But before we add additional features, let's first have a look how we pass data to this model before we go about initializing our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f610de",
   "metadata": {},
   "source": [
    "### Passing data to a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29580903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>group</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.403762</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.360060</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.198817</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.137271</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.093835</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.432290</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.100604</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.273164</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.128217</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.271851</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.331329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.192420</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.162030</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.233797</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.137968</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.214622</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.321909</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.153820</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.412021</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.102112</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.203671</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.068691</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.373918</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.098297</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.432786</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.222267</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.433867</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.385616</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.042390</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value  group  time_idx\n",
       "0   0.125697      0         0\n",
       "1   0.403762      0         1\n",
       "2   0.360060      0         2\n",
       "3  -0.198817      0         3\n",
       "4  -0.137271      0         4\n",
       "5   0.093835      0         5\n",
       "6  -0.432290      0         6\n",
       "7   0.100604      0         7\n",
       "8   0.273164      0         8\n",
       "9  -0.128217      0         9\n",
       "10 -0.271851      1         0\n",
       "11  0.331329      1         1\n",
       "12 -0.192420      1         2\n",
       "13 -0.162030      1         3\n",
       "14  0.233797      1         4\n",
       "15 -0.137968      1         5\n",
       "16 -0.214622      1         6\n",
       "17 -0.321909      1         7\n",
       "18  0.153820      1         8\n",
       "19  0.412021      1         9\n",
       "20  0.102112      2         0\n",
       "21  0.203671      2         1\n",
       "22  0.068691      2         2\n",
       "23  0.373918      2         3\n",
       "24  0.098297      2         4\n",
       "25 -0.432786      2         5\n",
       "26 -0.222267      2         6\n",
       "27  0.433867      2         7\n",
       "28 -0.385616      2         8\n",
       "29 -0.042390      2         9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test_data = pd.DataFrame(\n",
    "    dict(\n",
    "        value=np.random.rand(30) - 0.5,\n",
    "        group=np.repeat(np.arange(3), 10),\n",
    "        time_idx=np.tile(np.arange(10), 3),\n",
    "    )\n",
    ")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d1fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "# create the dataset from the pandas dataframe\n",
    "dataset = TimeSeriesDataSet(\n",
    "    test_data,\n",
    "    group_ids=[\"group\"],\n",
    "    target=\"value\",\n",
    "    time_idx=\"time_idx\",\n",
    "    min_encoder_length=5,\n",
    "    max_encoder_length=5,\n",
    "    min_prediction_length=2,\n",
    "    max_prediction_length=2,\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d35345c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_idx': 'time_idx',\n",
       " 'target': 'value',\n",
       " 'group_ids': ['group'],\n",
       " 'weight': None,\n",
       " 'max_encoder_length': 5,\n",
       " 'min_encoder_length': 5,\n",
       " 'min_prediction_idx': 0,\n",
       " 'min_prediction_length': 2,\n",
       " 'max_prediction_length': 2,\n",
       " 'static_categoricals': [],\n",
       " 'static_reals': [],\n",
       " 'time_varying_known_categoricals': [],\n",
       " 'time_varying_known_reals': [],\n",
       " 'time_varying_unknown_categoricals': [],\n",
       " 'time_varying_unknown_reals': ['value'],\n",
       " 'variable_groups': {},\n",
       " 'constant_fill_strategy': {},\n",
       " 'allow_missing_timesteps': False,\n",
       " 'lags': {},\n",
       " 'add_relative_time_idx': False,\n",
       " 'add_target_scales': False,\n",
       " 'add_encoder_length': False,\n",
       " 'target_normalizer': GroupNormalizer(),\n",
       " 'categorical_encoders': {'__group_id__group': NaNLabelEncoder(),\n",
       "  'group': NaNLabelEncoder()},\n",
       " 'scalers': {},\n",
       " 'randomize_length': None,\n",
       " 'predict_mode': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b62915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = {'encoder_cat': tensor([], size=(4, 5, 0), dtype=torch.int64), 'encoder_cont': tensor([[[ 1.1905],\n",
      "         [-0.7886],\n",
      "         [-0.6738],\n",
      "         [ 0.8220],\n",
      "         [-0.5828]],\n",
      "\n",
      "        [[ 1.3514],\n",
      "         [ 0.3099],\n",
      "         [-1.6969],\n",
      "         [-0.9014],\n",
      "         [ 1.5780]],\n",
      "\n",
      "        [[-0.8128],\n",
      "         [-0.5802],\n",
      "         [ 0.2931],\n",
      "         [-1.6950],\n",
      "         [ 0.3187]],\n",
      "\n",
      "        [[ 0.4135],\n",
      "         [ 1.4642],\n",
      "         [ 1.2991],\n",
      "         [-0.8128],\n",
      "         [-0.5802]]]), 'encoder_target': tensor([[ 0.3313, -0.1924, -0.1620,  0.2338, -0.1380],\n",
      "        [ 0.3739,  0.0983, -0.4328, -0.2223,  0.4339],\n",
      "        [-0.1988, -0.1373,  0.0938, -0.4323,  0.1006],\n",
      "        [ 0.1257,  0.4038,  0.3601, -0.1988, -0.1373]]), 'encoder_lengths': tensor([5, 5, 5, 5]), 'decoder_cat': tensor([], size=(4, 2, 0), dtype=torch.int64), 'decoder_cont': tensor([[[-0.8725],\n",
      "         [-1.2779]],\n",
      "\n",
      "        [[-1.5186],\n",
      "         [-0.2217]],\n",
      "\n",
      "        [[ 0.9707],\n",
      "         [-0.5460]],\n",
      "\n",
      "        [[ 0.2931],\n",
      "         [-1.6950]]]), 'decoder_target': tensor([[-0.2146, -0.3219],\n",
      "        [-0.3856, -0.0424],\n",
      "        [ 0.2732, -0.1282],\n",
      "        [ 0.0938, -0.4323]]), 'decoder_lengths': tensor([2, 2, 2, 2]), 'decoder_time_idx': tensor([[6, 7],\n",
      "        [8, 9],\n",
      "        [8, 9],\n",
      "        [5, 6]]), 'groups': tensor([[1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0]]), 'target_scale': tensor([[0.0163, 0.2646],\n",
      "        [0.0163, 0.2646],\n",
      "        [0.0163, 0.2646],\n",
      "        [0.0163, 0.2646]])}\n",
      "\n",
      "y = (tensor([[-0.2146, -0.3219],\n",
      "        [-0.3856, -0.0424],\n",
      "        [ 0.2732, -0.1282],\n",
      "        [ 0.0938, -0.4323]]), None)\n",
      "\n",
      "sizes of x =\n",
      "\tencoder_cat = torch.Size([4, 5, 0])\n",
      "\tencoder_cont = torch.Size([4, 5, 1])\n",
      "\tencoder_target = torch.Size([4, 5])\n",
      "\tencoder_lengths = torch.Size([4])\n",
      "\tdecoder_cat = torch.Size([4, 2, 0])\n",
      "\tdecoder_cont = torch.Size([4, 2, 1])\n",
      "\tdecoder_target = torch.Size([4, 2])\n",
      "\tdecoder_lengths = torch.Size([4])\n",
      "\tdecoder_time_idx = torch.Size([4, 2])\n",
      "\tgroups = torch.Size([4, 1])\n",
      "\ttarget_scale = torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "# convert the dataset to a dataloader\n",
    "dataloader = dataset.to_dataloader(batch_size=4)\n",
    "\n",
    "# and load the first batch\n",
    "x, y = next(iter(dataloader))\n",
    "print(\"x =\", x)\n",
    "print(\"\\ny =\", y)\n",
    "print(\"\\nsizes of x =\")\n",
    "for key, value in x.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2776b0b5",
   "metadata": {},
   "source": [
    "This explains why we had to first extract the correct input in our simple FullyConnectedModel above before passing it to our FullyConnectedModule. As a reminder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bde0d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "    # x is a batch generated based on the TimeSeriesDataset\n",
    "    network_input = x[\"encoder_cont\"].squeeze(-1)\n",
    "    prediction = self.network(network_input)\n",
    "\n",
    "    # rescale predictions into target space\n",
    "    prediction = self.transform_output(prediction, target_scale=x[\"target_scale\"])\n",
    "\n",
    "    # We need to return a dictionary that at least contains the prediction\n",
    "    # The parameter can be directly forwarded from the input.\n",
    "    # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "    return self.to_network_output(prediction=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad50aed",
   "metadata": {},
   "source": [
    "For such a simple architecture, we can ignore most of the inputs in x. You do not have to worry about moving tensors to specifc GPUs, PyTorch Lightning will take care of this for you.\n",
    "\n",
    "Now, let's check if our model works. We initialize model always with their from_dataset() method with takes hyperparameters from the dataset, hyperparameters for the model and hyperparameters for the optimizer. Read more about it in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09ab8399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output(prediction=tensor([[0.1097, 0.0525],\n",
       "        [0.1010, 0.0457],\n",
       "        [0.1001, 0.0422],\n",
       "        [0.1156, 0.0545]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FullyConnectedModel.from_dataset(\n",
    "    dataset, input_size=5, output_size=2, hidden_size=10, n_hidden_layers=2\n",
    ")\n",
    "x, y = next(iter(dataloader))\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b23dcdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_idx</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_idx  group\n",
       "0         7      1\n",
       "1         5      0\n",
       "2         6      2\n",
       "3         5      2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.x_to_index(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ddf543",
   "metadata": {},
   "source": [
    "### Coupling datasets and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a87eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedModel(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        hidden_size: int,\n",
    "        n_hidden_layers: int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "        self.network = FullyConnectedModule(\n",
    "            input_size=self.hparams.input_size,\n",
    "            output_size=self.hparams.output_size,\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            n_hidden_layers=self.hparams.n_hidden_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        network_input = x[\"encoder_cont\"].squeeze(-1)\n",
    "        prediction = self.network(network_input).unsqueeze(-1)\n",
    "\n",
    "        # rescale predictions into target space\n",
    "        prediction = self.transform_output(prediction, target_scale=x[\"target_scale\"])\n",
    "\n",
    "        # We need to return a dictionary that at least contains the prediction.\n",
    "        # The parameter can be directly forwarded from the input.\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset: TimeSeriesDataSet, **kwargs):\n",
    "        new_kwargs = {\n",
    "            \"output_size\": dataset.max_prediction_length,\n",
    "            \"input_size\": dataset.max_encoder_length,\n",
    "        }\n",
    "        new_kwargs.update(\n",
    "            kwargs\n",
    "        )  # use to pass real hyperparameters and override defaults set by dataset\n",
    "        # example for dataset validation\n",
    "        assert (\n",
    "            dataset.max_prediction_length == dataset.min_prediction_length\n",
    "        ), \"Decoder only supports a fixed length\"\n",
    "        assert (\n",
    "            dataset.min_encoder_length == dataset.max_encoder_length\n",
    "        ), \"Encoder only supports a fixed length\"\n",
    "        assert (\n",
    "            len(dataset.time_varying_known_categoricals) == 0\n",
    "            and len(dataset.time_varying_known_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_categoricals) == 0\n",
    "            and len(dataset.static_categoricals) == 0\n",
    "            and len(dataset.static_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_reals) == 1\n",
    "            and dataset.time_varying_unknown_reals[0] == dataset.target\n",
    "        ), \"Only covariate should be the target in 'time_varying_unknown_reals'\"\n",
    "\n",
    "        return super().from_dataset(dataset, **new_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2547942e",
   "metadata": {},
   "source": [
    "Now, let's initialize from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dac0c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/Python/python-3.9.6/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py:1726: LightningDeprecationWarning: Argument `mode` in `LightningModule.summarize` is deprecated in v1.4 and will be removed in v1.6. Use `max_depth=-1` to replicate `mode=full` behavior.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "   | Name                 | Type                 | Params\n",
      "---------------------------------------------------------------\n",
      "0  | loss                 | SMAPE                | 0     \n",
      "1  | logging_metrics      | ModuleList           | 0     \n",
      "2  | network              | FullyConnectedModule | 302   \n",
      "3  | network.sequential   | Sequential           | 302   \n",
      "4  | network.sequential.0 | Linear               | 60    \n",
      "5  | network.sequential.1 | ReLU                 | 0     \n",
      "6  | network.sequential.2 | Linear               | 110   \n",
      "7  | network.sequential.3 | ReLU                 | 0     \n",
      "8  | network.sequential.4 | Linear               | 110   \n",
      "9  | network.sequential.5 | ReLU                 | 0     \n",
      "10 | network.sequential.6 | Linear               | 22    \n",
      "---------------------------------------------------------------\n",
      "302       Trainable params\n",
      "0         Non-trainable params\n",
      "302       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"hidden_size\":                10\n",
       "\"input_size\":                 5\n",
       "\"learning_rate\":              0.001\n",
       "\"log_gradient_flow\":          False\n",
       "\"log_interval\":               -1\n",
       "\"log_val_interval\":           -1\n",
       "\"logging_metrics\":            ModuleList()\n",
       "\"monotone_constaints\":        {}\n",
       "\"n_hidden_layers\":            2\n",
       "\"optimizer\":                  ranger\n",
       "\"optimizer_params\":           None\n",
       "\"output_size\":                2\n",
       "\"output_transformer\":         GroupNormalizer()\n",
       "\"reduce_on_plateau_min_lr\":   1e-05\n",
       "\"reduce_on_plateau_patience\": 1000\n",
       "\"weight_decay\":               0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FullyConnectedModel.from_dataset(dataset, hidden_size=10, n_hidden_layers=2)\n",
    "model.summarize(\"full\")  # print model summary\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb9abd",
   "metadata": {},
   "source": [
    "### Defining additional hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "956cad27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hidden_size\":                10\n",
       "\"input_size\":                 5\n",
       "\"learning_rate\":              0.001\n",
       "\"log_gradient_flow\":          False\n",
       "\"log_interval\":               -1\n",
       "\"log_val_interval\":           -1\n",
       "\"logging_metrics\":            ModuleList()\n",
       "\"monotone_constaints\":        {}\n",
       "\"n_hidden_layers\":            2\n",
       "\"optimizer\":                  ranger\n",
       "\"optimizer_params\":           None\n",
       "\"output_size\":                2\n",
       "\"output_transformer\":         GroupNormalizer()\n",
       "\"reduce_on_plateau_min_lr\":   1e-05\n",
       "\"reduce_on_plateau_patience\": 1000\n",
       "\"weight_decay\":               0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a337738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        BaseModel for timeseries forecasting from which to inherit from\n",
      "\n",
      "        Args:\n",
      "            log_interval (Union[int, float], optional): Batches after which predictions are logged. If < 1.0, will log\n",
      "                multiple entries per batch. Defaults to -1.\n",
      "            log_val_interval (Union[int, float], optional): batches after which predictions for validation are\n",
      "                logged. Defaults to None/log_interval.\n",
      "            learning_rate (float, optional): Learning rate. Defaults to 1e-3.\n",
      "            log_gradient_flow (bool): If to log gradient flow, this takes time and should be only done to diagnose\n",
      "                training failures. Defaults to False.\n",
      "            loss (Metric, optional): metric to optimize, can also be list of metrics. Defaults to SMAPE().\n",
      "            logging_metrics (nn.ModuleList[MultiHorizonMetric]): list of metrics that are logged during training.\n",
      "                Defaults to [].\n",
      "            reduce_on_plateau_patience (int): patience after which learning rate is reduced by a factor of 10. Defaults\n",
      "                to 1000\n",
      "            reduce_on_plateau_min_lr (float): minimum learning rate for reduce on plateua learning rate scheduler.\n",
      "                Defaults to 1e-5\n",
      "            weight_decay (float): weight decay. Defaults to 0.0.\n",
      "            optimizer_params (Dict[str, Any]): additional parameters for the optimizer. Defaults to {}.\n",
      "            monotone_constaints (Dict[str, int]): dictionary of monotonicity constraints for continuous decoder\n",
      "                variables mapping\n",
      "                position (e.g. ``\"0\"`` for first position) to constraint (``-1`` for negative and ``+1`` for positive,\n",
      "                larger numbers add more weight to the constraint vs. the loss but are usually not necessary).\n",
      "                This constraint significantly slows down training. Defaults to {}.\n",
      "            output_transformer (Callable): transformer that takes network output and transforms it to prediction space.\n",
      "                Defaults to None which is equivalent to ``lambda out: out[\"prediction\"]``.\n",
      "            optimizer (str): Optimizer, \"ranger\", \"sgd\", \"adam\", \"adamw\" or class name of optimizer in ``torch.optim``.\n",
      "                Alternatively, a class or function can be passed which takes parameters as first argument and\n",
      "                a `lr` argument (optionally also `weight_decay`)\n",
      "                Defaults to \"ranger\".\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(BaseModel.__init__.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e864b23",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ede34b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>value</th>\n",
       "      <th>group</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>0.276194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0.923356</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>0.894203</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>0.891172</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>0.876182</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>0.955440</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>0.484344</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>0.125132</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>0.081989</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C</td>\n",
       "      <td>0.695326</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A</td>\n",
       "      <td>0.539564</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A</td>\n",
       "      <td>0.883346</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A</td>\n",
       "      <td>0.044368</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B</td>\n",
       "      <td>0.721034</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A</td>\n",
       "      <td>0.481008</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A</td>\n",
       "      <td>0.892619</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C</td>\n",
       "      <td>0.713021</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B</td>\n",
       "      <td>0.033343</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C</td>\n",
       "      <td>0.699104</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C</td>\n",
       "      <td>0.615121</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A</td>\n",
       "      <td>0.780146</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C</td>\n",
       "      <td>0.692293</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B</td>\n",
       "      <td>0.504597</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C</td>\n",
       "      <td>0.986720</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C</td>\n",
       "      <td>0.092079</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A</td>\n",
       "      <td>0.925435</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>B</td>\n",
       "      <td>0.912112</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>B</td>\n",
       "      <td>0.271425</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A</td>\n",
       "      <td>0.471866</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target     value  group  time_idx\n",
       "0       B  0.276194      0         0\n",
       "1       C  0.186486      0         1\n",
       "2       A  0.923356      0         2\n",
       "3       B  0.894203      0         3\n",
       "4       B  0.891172      0         4\n",
       "5       A  0.876182      0         5\n",
       "6       A  0.955440      0         6\n",
       "7       A  0.484344      0         7\n",
       "8       A  0.125132      0         8\n",
       "9       C  0.081989      0         9\n",
       "10      C  0.695326      1         0\n",
       "11      A  0.539564      1         1\n",
       "12      A  0.883346      1         2\n",
       "13      A  0.044368      1         3\n",
       "14      B  0.721034      1         4\n",
       "15      A  0.481008      1         5\n",
       "16      A  0.892619      1         6\n",
       "17      C  0.713021      1         7\n",
       "18      B  0.033343      1         8\n",
       "19      C  0.699104      1         9\n",
       "20      C  0.615121      2         0\n",
       "21      A  0.780146      2         1\n",
       "22      C  0.692293      2         2\n",
       "23      B  0.504597      2         3\n",
       "24      C  0.986720      2         4\n",
       "25      C  0.092079      2         5\n",
       "26      A  0.925435      2         6\n",
       "27      B  0.912112      2         7\n",
       "28      B  0.271425      2         8\n",
       "29      A  0.471866      2         9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_test_data = pd.DataFrame(\n",
    "    dict(\n",
    "        target=np.random.choice(\n",
    "            [\"A\", \"B\", \"C\"], size=30\n",
    "        ),  # CHANGING values to predict to a categorical\n",
    "        value=np.random.rand(\n",
    "            30\n",
    "        ),  # INPUT values - see next section on covariates how to use categorical inputs\n",
    "        group=np.repeat(np.arange(3), 10),\n",
    "        time_idx=np.tile(np.arange(10), 3),\n",
    "    )\n",
    ")\n",
    "classification_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aaf43ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "\n",
    "# create the dataset from the pandas dataframe\n",
    "classification_dataset = TimeSeriesDataSet(\n",
    "    classification_test_data,\n",
    "    group_ids=[\"group\"],\n",
    "    target=\"target\",  # SWITCHING to categorical target\n",
    "    time_idx=\"time_idx\",\n",
    "    min_encoder_length=5,\n",
    "    max_encoder_length=5,\n",
    "    min_prediction_length=2,\n",
    "    max_prediction_length=2,\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    target_normalizer=NaNLabelEncoder(),  # Use the NaNLabelEncoder to encode categorical target\n",
    ")\n",
    "\n",
    "x, y = next(iter(classification_dataset.to_dataloader(batch_size=4)))\n",
    "y[0]  # target values are encoded categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a2369f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/Python/python-3.9.6/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py:1726: LightningDeprecationWarning: Argument `mode` in `LightningModule.summarize` is deprecated in v1.4 and will be removed in v1.6. Use `max_depth=-1` to replicate `mode=full` behavior.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "   | Name                 | Type                 | Params\n",
      "---------------------------------------------------------------\n",
      "0  | loss                 | SMAPE                | 0     \n",
      "1  | logging_metrics      | ModuleList           | 0     \n",
      "2  | network              | FullyConnectedModule | 346   \n",
      "3  | network.sequential   | Sequential           | 346   \n",
      "4  | network.sequential.0 | Linear               | 60    \n",
      "5  | network.sequential.1 | ReLU                 | 0     \n",
      "6  | network.sequential.2 | Linear               | 110   \n",
      "7  | network.sequential.3 | ReLU                 | 0     \n",
      "8  | network.sequential.4 | Linear               | 110   \n",
      "9  | network.sequential.5 | ReLU                 | 0     \n",
      "10 | network.sequential.6 | Linear               | 66    \n",
      "---------------------------------------------------------------\n",
      "346       Trainable params\n",
      "0         Non-trainable params\n",
      "346       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"hidden_size\":                10\n",
       "\"input_size\":                 5\n",
       "\"learning_rate\":              0.001\n",
       "\"log_gradient_flow\":          False\n",
       "\"log_interval\":               -1\n",
       "\"log_val_interval\":           -1\n",
       "\"logging_metrics\":            ModuleList()\n",
       "\"monotone_constaints\":        {}\n",
       "\"n_classes\":                  3\n",
       "\"n_hidden_layers\":            2\n",
       "\"optimizer\":                  ranger\n",
       "\"optimizer_params\":           None\n",
       "\"output_size\":                2\n",
       "\"output_transformer\":         NaNLabelEncoder()\n",
       "\"reduce_on_plateau_min_lr\":   1e-05\n",
       "\"reduce_on_plateau_patience\": 1000\n",
       "\"weight_decay\":               0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_forecasting.metrics import CrossEntropy\n",
    "\n",
    "\n",
    "class FullyConnectedClassificationModel(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        hidden_size: int,\n",
    "        n_hidden_layers: int,\n",
    "        n_classes: int,\n",
    "        loss=CrossEntropy(),\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "        self.network = FullyConnectedModule(\n",
    "            input_size=self.hparams.input_size,\n",
    "            output_size=self.hparams.output_size * self.hparams.n_classes,\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            n_hidden_layers=self.hparams.n_hidden_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        batch_size = x[\"encoder_cont\"].size(0)\n",
    "        network_input = x[\"encoder_cont\"].squeeze(-1)\n",
    "        prediction = self.network(network_input)\n",
    "        # RESHAPE output to batch_size x n_decoder_timesteps x n_classes\n",
    "        prediction = prediction.unsqueeze(-1).view(\n",
    "            batch_size, -1, self.hparams.n_classes\n",
    "        )\n",
    "\n",
    "        # rescale predictions into target space\n",
    "        prediction = self.transform_output(prediction, target_scale=x[\"target_scale\"])\n",
    "\n",
    "        # We need to return a named tuple that at least contains the prediction.\n",
    "        # The parameter can be directly forwarded from the input.\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset: TimeSeriesDataSet, **kwargs):\n",
    "        assert isinstance(\n",
    "            dataset.target_normalizer, NaNLabelEncoder\n",
    "        ), \"target normalizer has to encode categories\"\n",
    "        new_kwargs = {\n",
    "            \"n_classes\": len(\n",
    "                dataset.target_normalizer.classes_\n",
    "            ),  # ADD number of classes as encoded by the target normalizer\n",
    "            \"output_size\": dataset.max_prediction_length,\n",
    "            \"input_size\": dataset.max_encoder_length,\n",
    "        }\n",
    "        new_kwargs.update(\n",
    "            kwargs\n",
    "        )  # use to pass real hyperparameters and override defaults set by dataset\n",
    "        # example for dataset validation\n",
    "        assert (\n",
    "            dataset.max_prediction_length == dataset.min_prediction_length\n",
    "        ), \"Decoder only supports a fixed length\"\n",
    "        assert (\n",
    "            dataset.min_encoder_length == dataset.max_encoder_length\n",
    "        ), \"Encoder only supports a fixed length\"\n",
    "        assert (\n",
    "            len(dataset.time_varying_known_categoricals) == 0\n",
    "            and len(dataset.time_varying_known_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_categoricals) == 0\n",
    "            and len(dataset.static_categoricals) == 0\n",
    "            and len(dataset.static_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_reals) == 1\n",
    "        ), \"Only covariate should be in 'time_varying_unknown_reals'\"\n",
    "\n",
    "        return super().from_dataset(dataset, **new_kwargs)\n",
    "\n",
    "\n",
    "model = FullyConnectedClassificationModel.from_dataset(\n",
    "    classification_dataset, hidden_size=10, n_hidden_layers=2\n",
    ")\n",
    "model.summarize(\"full\")\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52fa6809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passing x through model\n",
    "model(x)[\"prediction\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be1db3",
   "metadata": {},
   "source": [
    "## Predicting multiple targets at the same time\n",
    "Training a model to predict multiple targets simulateneously is not difficult to implement. We can even employ mixed targets, i.e. a mix of categorical and continous targets. The first step is to use define a dataframe with multiple targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2965a2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>group</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.343665</td>\n",
       "      <td>0.516140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608444</td>\n",
       "      <td>0.571139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.159687</td>\n",
       "      <td>0.851720</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.954097</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.259125</td>\n",
       "      <td>0.474496</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.669304</td>\n",
       "      <td>0.675852</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.766701</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.351634</td>\n",
       "      <td>0.288928</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.034312</td>\n",
       "      <td>0.845248</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.504706</td>\n",
       "      <td>0.325650</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.991782</td>\n",
       "      <td>0.533199</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.939053</td>\n",
       "      <td>0.541625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.738001</td>\n",
       "      <td>0.663786</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.451444</td>\n",
       "      <td>0.370573</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.408092</td>\n",
       "      <td>0.721669</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.287386</td>\n",
       "      <td>0.939159</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.567734</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.245404</td>\n",
       "      <td>0.123680</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.959193</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.854039</td>\n",
       "      <td>0.916272</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.369633</td>\n",
       "      <td>0.517887</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.932242</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.052223</td>\n",
       "      <td>0.910320</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.765801</td>\n",
       "      <td>0.404287</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.773394</td>\n",
       "      <td>0.361251</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.512848</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.785202</td>\n",
       "      <td>0.270307</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.355509</td>\n",
       "      <td>0.532399</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.727400</td>\n",
       "      <td>0.056927</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.129796</td>\n",
       "      <td>0.841360</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target1   target2  group  time_idx\n",
       "0   0.343665  0.516140      0         0\n",
       "1   0.608444  0.571139      0         1\n",
       "2   0.159687  0.851720      0         2\n",
       "3   0.885167  0.954097      0         3\n",
       "4   0.259125  0.474496      0         4\n",
       "5   0.669304  0.675852      0         5\n",
       "6   0.766701  0.020324      0         6\n",
       "7   0.351634  0.288928      0         7\n",
       "8   0.034312  0.845248      0         8\n",
       "9   0.504706  0.325650      0         9\n",
       "10  0.991782  0.533199      1         0\n",
       "11  0.939053  0.541625      1         1\n",
       "12  0.738001  0.663786      1         2\n",
       "13  0.451444  0.370573      1         3\n",
       "14  0.408092  0.721669      1         4\n",
       "15  0.287386  0.939159      1         5\n",
       "16  0.567734  0.006656      1         6\n",
       "17  0.245404  0.123680      1         7\n",
       "18  0.768240  0.959193      1         8\n",
       "19  0.854039  0.916272      1         9\n",
       "20  0.369633  0.517887      2         0\n",
       "21  0.667559  0.932242      2         1\n",
       "22  0.052223  0.910320      2         2\n",
       "23  0.765801  0.404287      2         3\n",
       "24  0.773394  0.361251      2         4\n",
       "25  0.974026  0.512848      2         5\n",
       "26  0.785202  0.270307      2         6\n",
       "27  0.355509  0.532399      2         7\n",
       "28  0.727400  0.056927      2         8\n",
       "29  0.129796  0.841360      2         9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_target_test_data = pd.DataFrame(\n",
    "    dict(\n",
    "        target1=np.random.rand(30),\n",
    "        target2=np.random.rand(30),\n",
    "        group=np.repeat(np.arange(3), 10),\n",
    "        time_idx=np.tile(np.arange(10), 3),\n",
    "    )\n",
    ")\n",
    "multi_target_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29d4a6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.3555, 0.7274],\n",
       "         [0.3516, 0.0343],\n",
       "         [0.9740, 0.7852],\n",
       "         [0.7682, 0.8540]]),\n",
       " tensor([[0.5324, 0.0569],\n",
       "         [0.2889, 0.8452],\n",
       "         [0.5128, 0.2703],\n",
       "         [0.9592, 0.9163]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_forecasting.data.encoders import (\n",
    "    EncoderNormalizer,\n",
    "    MultiNormalizer,\n",
    "    TorchNormalizer,\n",
    ")\n",
    "\n",
    "# create the dataset from the pandas dataframe\n",
    "multi_target_dataset = TimeSeriesDataSet(\n",
    "    multi_target_test_data,\n",
    "    group_ids=[\"group\"],\n",
    "    target=[\"target1\", \"target2\"],  # USING two targets\n",
    "    time_idx=\"time_idx\",\n",
    "    min_encoder_length=5,\n",
    "    max_encoder_length=5,\n",
    "    min_prediction_length=2,\n",
    "    max_prediction_length=2,\n",
    "    time_varying_unknown_reals=[\"target1\", \"target2\"],\n",
    "    target_normalizer=MultiNormalizer(\n",
    "        [EncoderNormalizer(), TorchNormalizer()]\n",
    "    ),  # Use the NaNLabelEncoder to encode categorical target\n",
    ")\n",
    "\n",
    "x, y = next(iter(multi_target_dataset.to_dataloader(batch_size=4)))\n",
    "y[0]  # target values are a list of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fad2da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/Python/python-3.9.6/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py:1726: LightningDeprecationWarning: Argument `mode` in `LightningModule.summarize` is deprecated in v1.4 and will be removed in v1.6. Use `max_depth=-1` to replicate `mode=full` behavior.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "   | Name                 | Type                 | Params\n",
      "---------------------------------------------------------------\n",
      "0  | loss                 | MultiLoss            | 0     \n",
      "1  | logging_metrics      | ModuleList           | 0     \n",
      "2  | network              | FullyConnectedModule | 374   \n",
      "3  | network.sequential   | Sequential           | 374   \n",
      "4  | network.sequential.0 | Linear               | 110   \n",
      "5  | network.sequential.1 | ReLU                 | 0     \n",
      "6  | network.sequential.2 | Linear               | 110   \n",
      "7  | network.sequential.3 | ReLU                 | 0     \n",
      "8  | network.sequential.4 | Linear               | 110   \n",
      "9  | network.sequential.5 | ReLU                 | 0     \n",
      "10 | network.sequential.6 | Linear               | 44    \n",
      "---------------------------------------------------------------\n",
      "374       Trainable params\n",
      "0         Non-trainable params\n",
      "374       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"hidden_size\":                10\n",
       "\"input_size\":                 5\n",
       "\"learning_rate\":              0.001\n",
       "\"log_gradient_flow\":          False\n",
       "\"log_interval\":               -1\n",
       "\"log_val_interval\":           -1\n",
       "\"logging_metrics\":            ModuleList()\n",
       "\"monotone_constaints\":        {}\n",
       "\"n_hidden_layers\":            2\n",
       "\"optimizer\":                  ranger\n",
       "\"optimizer_params\":           None\n",
       "\"output_size\":                2\n",
       "\"output_transformer\":         MultiNormalizer(normalizers=[EncoderNormalizer(), TorchNormalizer()])\n",
       "\"reduce_on_plateau_min_lr\":   1e-05\n",
       "\"reduce_on_plateau_patience\": 1000\n",
       "\"target_sizes\":               [1, 1]\n",
       "\"weight_decay\":               0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, MultiLoss\n",
    "from pytorch_forecasting.utils import to_list\n",
    "\n",
    "\n",
    "class FullyConnectedMultiTargetModel(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        hidden_size: int,\n",
    "        n_hidden_layers: int,\n",
    "        target_sizes: Union[int, List[int]] = [],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "        self.network = FullyConnectedModule(\n",
    "            input_size=self.hparams.input_size\n",
    "            * len(to_list(self.hparams.target_sizes)),\n",
    "            output_size=self.hparams.output_size\n",
    "            * sum(to_list(self.hparams.target_sizes)),\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            n_hidden_layers=self.hparams.n_hidden_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        batch_size = x[\"encoder_cont\"].size(0)\n",
    "        network_input = x[\"encoder_cont\"].view(batch_size, -1)\n",
    "        prediction = self.network(network_input)\n",
    "        # RESHAPE output to batch_size x n_decoder_timesteps x sum_of_target_sizes\n",
    "        prediction = prediction.unsqueeze(-1).view(\n",
    "            batch_size, self.hparams.output_size, sum(self.hparams.target_sizes)\n",
    "        )\n",
    "        # RESHAPE into list of batch_size x n_decoder_timesteps x target_sizes[i] where i=1..len(target_sizes)\n",
    "        stops = np.cumsum(self.hparams.target_sizes)\n",
    "        starts = stops - self.hparams.target_sizes\n",
    "        prediction = [prediction[..., start:stop] for start, stop in zip(starts, stops)]\n",
    "        if isinstance(self.hparams.target_sizes, int):  # only one target\n",
    "            prediction = prediction[0]\n",
    "\n",
    "        # rescale predictions into target space\n",
    "        prediction = self.transform_output(prediction, target_scale=x[\"target_scale\"])\n",
    "\n",
    "        # We need to return a named tuple that at least contains the prediction.\n",
    "        # The parameter can be directly forwarded from the input.\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset: TimeSeriesDataSet, **kwargs):\n",
    "        # By default only handle targets of size one here, categorical targets would be of larger size\n",
    "        new_kwargs = {\n",
    "            \"target_sizes\": [1] * len(to_list(dataset.target)),\n",
    "            \"output_size\": dataset.max_prediction_length,\n",
    "            \"input_size\": dataset.max_encoder_length,\n",
    "        }\n",
    "        new_kwargs.update(\n",
    "            kwargs\n",
    "        )  # use to pass real hyperparameters and override defaults set by dataset\n",
    "        # example for dataset validation\n",
    "        assert (\n",
    "            dataset.max_prediction_length == dataset.min_prediction_length\n",
    "        ), \"Decoder only supports a fixed length\"\n",
    "        assert (\n",
    "            dataset.min_encoder_length == dataset.max_encoder_length\n",
    "        ), \"Encoder only supports a fixed length\"\n",
    "        assert (\n",
    "            len(dataset.time_varying_known_categoricals) == 0\n",
    "            and len(dataset.time_varying_known_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_categoricals) == 0\n",
    "            and len(dataset.static_categoricals) == 0\n",
    "            and len(dataset.static_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_reals)\n",
    "            == len(dataset.target_names)  # Expect as as many unknown reals as targets\n",
    "        ), \"Only covariate should be in 'time_varying_unknown_reals'\"\n",
    "\n",
    "        return super().from_dataset(dataset, **new_kwargs)\n",
    "\n",
    "\n",
    "model = FullyConnectedMultiTargetModel.from_dataset(\n",
    "    multi_target_dataset,\n",
    "    hidden_size=10,\n",
    "    n_hidden_layers=2,\n",
    "    loss=MultiLoss(metrics=[MAE(), SMAPE()], weights=[2.0, 1.0]),\n",
    ")\n",
    "model.summarize(\"full\")\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbb21972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output(prediction=[tensor([[[0.7428],\n",
       "         [0.6436]],\n",
       "\n",
       "        [[0.6099],\n",
       "         [0.5157]],\n",
       "\n",
       "        [[0.5959],\n",
       "         [0.4909]],\n",
       "\n",
       "        [[0.4156],\n",
       "         [0.3782]]], grad_fn=<AddBackward0>), tensor([[[0.4682],\n",
       "         [0.5384]],\n",
       "\n",
       "        [[0.4769],\n",
       "         [0.5505]],\n",
       "\n",
       "        [[0.4573],\n",
       "         [0.5471]],\n",
       "\n",
       "        [[0.4699],\n",
       "         [0.5610]]], dtype=torch.float64, grad_fn=<AddBackward0>)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(x)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03cac361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2549, dtype=torch.float64, grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss(out[\"prediction\"], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b20b7",
   "metadata": {},
   "source": [
    "## Using covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "214665f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Model with additional methods using covariates.\n",
      "\n",
      "    Assumes the following hyperparameters:\n",
      "\n",
      "    Args:\n",
      "        static_categoricals (List[str]): names of static categorical variables\n",
      "        static_reals (List[str]): names of static continuous variables\n",
      "        time_varying_categoricals_encoder (List[str]): names of categorical variables for encoder\n",
      "        time_varying_categoricals_decoder (List[str]): names of categorical variables for decoder\n",
      "        time_varying_reals_encoder (List[str]): names of continuous variables for encoder\n",
      "        time_varying_reals_decoder (List[str]): names of continuous variables for decoder\n",
      "        x_reals (List[str]): order of continuous variables in tensor passed to forward function\n",
      "        x_categoricals (List[str]): order of categorical variables in tensor passed to forward function\n",
      "        embedding_sizes (Dict[str, Tuple[int, int]]): dictionary mapping categorical variables to tuple of integers\n",
      "            where the first integer denotes the number of categorical classes and the second the embedding size\n",
      "        embedding_labels (Dict[str, List[str]]): dictionary mapping (string) indices to list of categorical labels\n",
      "        embedding_paddings (List[str]): names of categorical variables for which label 0 is always mapped to an\n",
      "             embedding vector filled with zeros\n",
      "        categorical_groups (Dict[str, List[str]]): dictionary of categorical variables that are grouped together and\n",
      "            can also take multiple values simultaneously (e.g. holiday during octoberfest). They should be implemented\n",
      "            as bag of embeddings\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting.models.base_model import BaseModelWithCovariates\n",
    "\n",
    "print(BaseModelWithCovariates.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1feb6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from pytorch_forecasting.models.nn import MultiEmbedding\n",
    "\n",
    "\n",
    "class FullyConnectedModelWithCovariates(BaseModelWithCovariates):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        hidden_size: int,\n",
    "        n_hidden_layers: int,\n",
    "        x_reals: List[str],\n",
    "        x_categoricals: List[str],\n",
    "        embedding_sizes: Dict[str, Tuple[int, int]],\n",
    "        embedding_labels: Dict[str, List[str]],\n",
    "        static_categoricals: List[str],\n",
    "        static_reals: List[str],\n",
    "        time_varying_categoricals_encoder: List[str],\n",
    "        time_varying_categoricals_decoder: List[str],\n",
    "        time_varying_reals_encoder: List[str],\n",
    "        time_varying_reals_decoder: List[str],\n",
    "        embedding_paddings: List[str],\n",
    "        categorical_groups: Dict[str, List[str]],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # create embedder - can be fed with x[\"encoder_cat\"] or x[\"decoder_cat\"] and will return\n",
    "        # dictionary of category names mapped to embeddings\n",
    "        self.input_embeddings = MultiEmbedding(\n",
    "            embedding_sizes=self.hparams.embedding_sizes,\n",
    "            categorical_groups=self.hparams.categorical_groups,\n",
    "            embedding_paddings=self.hparams.embedding_paddings,\n",
    "            x_categoricals=self.hparams.x_categoricals,\n",
    "            max_embedding_size=self.hparams.hidden_size,\n",
    "        )\n",
    "\n",
    "        # calculate the size of all concatenated embeddings + continous variables\n",
    "        n_features = sum(\n",
    "            embedding_size\n",
    "            for classes_size, embedding_size in self.hparams.embedding_sizes.values()\n",
    "        ) + len(self.reals)\n",
    "\n",
    "        # create network that will be fed with continious variables and embeddings\n",
    "        self.network = FullyConnectedModule(\n",
    "            input_size=self.hparams.input_size * n_features,\n",
    "            output_size=self.hparams.output_size,\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            n_hidden_layers=self.hparams.n_hidden_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        batch_size = x[\"encoder_lengths\"].size(0)\n",
    "        embeddings = self.input_embeddings(\n",
    "            x[\"encoder_cat\"]\n",
    "        )  # returns dictionary with embedding tensors\n",
    "        network_input = torch.cat(\n",
    "            [x[\"encoder_cont\"]]\n",
    "            + [\n",
    "                emb\n",
    "                for name, emb in embeddings.items()\n",
    "                if name in self.encoder_variables or name in self.static_variables\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        prediction = self.network(network_input.view(batch_size, -1))\n",
    "\n",
    "        # rescale predictions into target space\n",
    "        prediction = self.transform_output(prediction, target_scale=x[\"target_scale\"])\n",
    "\n",
    "        # We need to return a dictionary that at least contains the prediction.\n",
    "        # The parameter can be directly forwarded from the input.\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset: TimeSeriesDataSet, **kwargs):\n",
    "        new_kwargs = {\n",
    "            \"output_size\": dataset.max_prediction_length,\n",
    "            \"input_size\": dataset.max_encoder_length,\n",
    "        }\n",
    "        new_kwargs.update(\n",
    "            kwargs\n",
    "        )  # use to pass real hyperparameters and override defaults set by dataset\n",
    "        # example for dataset validation\n",
    "        assert (\n",
    "            dataset.max_prediction_length == dataset.min_prediction_length\n",
    "        ), \"Decoder only supports a fixed length\"\n",
    "        assert (\n",
    "            dataset.min_encoder_length == dataset.max_encoder_length\n",
    "        ), \"Encoder only supports a fixed length\"\n",
    "\n",
    "        return super().from_dataset(dataset, **new_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5bda738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>group</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>categorical_covariate</th>\n",
       "      <th>real_covariate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.774005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0.333642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720550</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0.712037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.761146</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>0.444420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342583</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>0.819633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.946751</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>0.141854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.159947</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>b</td>\n",
       "      <td>0.533876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.887627</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>b</td>\n",
       "      <td>0.706678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.743960</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>0.687738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.605190</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "      <td>0.751191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.523593</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>a</td>\n",
       "      <td>0.955520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.128832</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0.800715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.084681</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0.810298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.365164</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>0.348042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.860333</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>0.145987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.709943</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>0.765362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.782830</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>b</td>\n",
       "      <td>0.269064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.163854</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>a</td>\n",
       "      <td>0.179178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.722940</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>0.802194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.968375</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>b</td>\n",
       "      <td>0.188320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.534986</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>a</td>\n",
       "      <td>0.845779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.358339</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>0.390114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.971790</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>0.408620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.566142</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>0.941383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.387604</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>0.428376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.666429</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>b</td>\n",
       "      <td>0.366654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.815022</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>b</td>\n",
       "      <td>0.009042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.881050</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>b</td>\n",
       "      <td>0.400715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.144155</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>0.346813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.856393</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>b</td>\n",
       "      <td>0.285717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.068322</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>a</td>\n",
       "      <td>0.078873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value group  time_idx categorical_covariate  real_covariate\n",
       "0   0.774005     0         0                     a        0.333642\n",
       "1   0.720550     0         1                     a        0.712037\n",
       "2   0.761146     0         2                     a        0.444420\n",
       "3   0.342583     0         3                     b        0.819633\n",
       "4   0.946751     0         4                     a        0.141854\n",
       "5   0.159947     0         5                     b        0.533876\n",
       "6   0.887627     0         6                     b        0.706678\n",
       "7   0.743960     0         7                     b        0.687738\n",
       "8   0.605190     0         8                     a        0.751191\n",
       "9   0.523593     0         9                     a        0.955520\n",
       "10  0.128832     1         0                     a        0.800715\n",
       "11  0.084681     1         1                     a        0.810298\n",
       "12  0.365164     1         2                     b        0.348042\n",
       "13  0.860333     1         3                     a        0.145987\n",
       "14  0.709943     1         4                     a        0.765362\n",
       "15  0.782830     1         5                     b        0.269064\n",
       "16  0.163854     1         6                     a        0.179178\n",
       "17  0.722940     1         7                     a        0.802194\n",
       "18  0.968375     1         8                     b        0.188320\n",
       "19  0.534986     1         9                     a        0.845779\n",
       "20  0.358339     2         0                     a        0.390114\n",
       "21  0.971790     2         1                     b        0.408620\n",
       "22  0.566142     2         2                     a        0.941383\n",
       "23  0.387604     2         3                     a        0.428376\n",
       "24  0.666429     2         4                     b        0.366654\n",
       "25  0.815022     2         5                     b        0.009042\n",
       "26  0.881050     2         6                     b        0.400715\n",
       "27  0.144155     2         7                     b        0.346813\n",
       "28  0.856393     2         8                     b        0.285717\n",
       "29  0.068322     2         9                     a        0.078873"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "test_data_with_covariates = pd.DataFrame(\n",
    "    dict(\n",
    "        # as before\n",
    "        value=np.random.rand(30),\n",
    "        group=np.repeat(np.arange(3), 10),\n",
    "        time_idx=np.tile(np.arange(10), 3),\n",
    "        # now adding covariates\n",
    "        categorical_covariate=np.random.choice([\"a\", \"b\"], size=30),\n",
    "        real_covariate=np.random.rand(30),\n",
    "    )\n",
    ").astype(\n",
    "    dict(group=str)\n",
    ")  # categorical covariates have to be of string type\n",
    "test_data_with_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "050f007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/Python/python-3.9.6/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py:1726: LightningDeprecationWarning: Argument `mode` in `LightningModule.summarize` is deprecated in v1.4 and will be removed in v1.6. Use `max_depth=-1` to replicate `mode=full` behavior.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "   | Name                                              | Type                 | Params\n",
      "--------------------------------------------------------------------------------------------\n",
      "0  | loss                                              | SMAPE                | 0     \n",
      "1  | logging_metrics                                   | ModuleList           | 0     \n",
      "2  | input_embeddings                                  | MultiEmbedding       | 11    \n",
      "3  | input_embeddings.embeddings                       | ModuleDict           | 11    \n",
      "4  | input_embeddings.embeddings.group                 | Embedding            | 9     \n",
      "5  | input_embeddings.embeddings.categorical_covariate | Embedding            | 2     \n",
      "6  | network                                           | FullyConnectedModule | 552   \n",
      "7  | network.sequential                                | Sequential           | 552   \n",
      "8  | network.sequential.0                              | Linear               | 310   \n",
      "9  | network.sequential.1                              | ReLU                 | 0     \n",
      "10 | network.sequential.2                              | Linear               | 110   \n",
      "11 | network.sequential.3                              | ReLU                 | 0     \n",
      "12 | network.sequential.4                              | Linear               | 110   \n",
      "13 | network.sequential.5                              | ReLU                 | 0     \n",
      "14 | network.sequential.6                              | Linear               | 22    \n",
      "--------------------------------------------------------------------------------------------\n",
      "563       Trainable params\n",
      "0         Non-trainable params\n",
      "563       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"categorical_groups\":                {}\n",
       "\"embedding_labels\":                  {'group': {'0': 0, '1': 1, '2': 2}, 'categorical_covariate': {'a': 0, 'b': 1}}\n",
       "\"embedding_paddings\":                []\n",
       "\"embedding_sizes\":                   {'group': [3, 3], 'categorical_covariate': [2, 1]}\n",
       "\"hidden_size\":                       10\n",
       "\"input_size\":                        5\n",
       "\"learning_rate\":                     0.001\n",
       "\"log_gradient_flow\":                 False\n",
       "\"log_interval\":                      -1\n",
       "\"log_val_interval\":                  -1\n",
       "\"logging_metrics\":                   ModuleList()\n",
       "\"monotone_constaints\":               {}\n",
       "\"n_hidden_layers\":                   2\n",
       "\"optimizer\":                         ranger\n",
       "\"optimizer_params\":                  None\n",
       "\"output_size\":                       2\n",
       "\"output_transformer\":                GroupNormalizer(transformation='relu')\n",
       "\"reduce_on_plateau_min_lr\":          1e-05\n",
       "\"reduce_on_plateau_patience\":        1000\n",
       "\"static_categoricals\":               ['group']\n",
       "\"static_reals\":                      []\n",
       "\"time_varying_categoricals_decoder\": ['categorical_covariate']\n",
       "\"time_varying_categoricals_encoder\": ['categorical_covariate']\n",
       "\"time_varying_reals_decoder\":        ['real_covariate']\n",
       "\"time_varying_reals_encoder\":        ['real_covariate', 'value']\n",
       "\"weight_decay\":                      0.0\n",
       "\"x_categoricals\":                    ['group', 'categorical_covariate']\n",
       "\"x_reals\":                           ['real_covariate', 'value']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the dataset from the pandas dataframe\n",
    "dataset_with_covariates = TimeSeriesDataSet(\n",
    "    test_data_with_covariates,\n",
    "    group_ids=[\"group\"],\n",
    "    target=\"value\",\n",
    "    time_idx=\"time_idx\",\n",
    "    min_encoder_length=5,\n",
    "    max_encoder_length=5,\n",
    "    min_prediction_length=2,\n",
    "    max_prediction_length=2,\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    time_varying_known_reals=[\"real_covariate\"],\n",
    "    time_varying_known_categoricals=[\"categorical_covariate\"],\n",
    "    static_categoricals=[\"group\"],\n",
    ")\n",
    "\n",
    "model = FullyConnectedModelWithCovariates.from_dataset(\n",
    "    dataset_with_covariates, hidden_size=10, n_hidden_layers=2\n",
    ")\n",
    "model.summarize(\"full\")  # print model summary\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "363e13a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output(prediction=tensor([[0.5737, 0.6066],\n",
       "        [0.5831, 0.6082],\n",
       "        [0.5680, 0.5922],\n",
       "        [0.5961, 0.6188]], grad_fn=<ClampBackward1>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dataset_with_covariates.to_dataloader(batch_size=4)))  # generate batch\n",
    "model(x)  # pass batch through model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c2645",
   "metadata": {},
   "source": [
    "## Implementing an autoregressive / recurrent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48f78a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | SMAPE      | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | lstm            | LSTM       | 1.4 K \n",
      "3 | output_layer    | Linear     | 11    \n",
      "-----------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"dropout\":                    0.1\n",
       "\"hidden_size\":                10\n",
       "\"learning_rate\":              0.001\n",
       "\"log_gradient_flow\":          False\n",
       "\"log_interval\":               -1\n",
       "\"log_val_interval\":           -1\n",
       "\"logging_metrics\":            ModuleList()\n",
       "\"monotone_constaints\":        {}\n",
       "\"n_layers\":                   2\n",
       "\"optimizer\":                  ranger\n",
       "\"optimizer_params\":           None\n",
       "\"output_transformer\":         GroupNormalizer()\n",
       "\"reduce_on_plateau_min_lr\":   1e-05\n",
       "\"reduce_on_plateau_patience\": 1000\n",
       "\"target\":                     value\n",
       "\"target_lags\":                {}\n",
       "\"weight_decay\":               0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils import rnn\n",
    "\n",
    "from pytorch_forecasting.models.base_model import AutoRegressiveBaseModel\n",
    "from pytorch_forecasting.models.nn import LSTM\n",
    "\n",
    "\n",
    "class LSTMModel(AutoRegressiveBaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        target: str,\n",
    "        target_lags: Dict[str, Dict[str, int]],\n",
    "        n_layers: int,\n",
    "        hidden_size: int,\n",
    "        dropout: float = 0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # arguments target and target_lags are required for autoregressive models\n",
    "        # even though target_lags cannot be used without covariates\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # use version of LSTM that can handle zero-length sequences\n",
    "        self.lstm = LSTM(\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            input_size=1,\n",
    "            num_layers=self.hparams.n_layers,\n",
    "            dropout=self.hparams.dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.output_layer = nn.Linear(self.hparams.hidden_size, 1)\n",
    "\n",
    "    def encode(self, x: Dict[str, torch.Tensor]):\n",
    "        # we need at least one encoding step as because the target needs to be lagged by one time step\n",
    "        # because we use the custom LSTM, we do not have to require encoder lengths of > 1\n",
    "        # but can handle lengths of >= 1\n",
    "        assert x[\"encoder_lengths\"].min() >= 1\n",
    "        input_vector = x[\"encoder_cont\"].clone()\n",
    "        # lag target by one\n",
    "        input_vector[..., self.target_positions] = torch.roll(\n",
    "            input_vector[..., self.target_positions], shifts=1, dims=1\n",
    "        )\n",
    "        input_vector = input_vector[\n",
    "            :, 1:\n",
    "        ]  # first time step cannot be used because of lagging\n",
    "\n",
    "        # determine effective encoder_length length\n",
    "        effective_encoder_lengths = x[\"encoder_lengths\"] - 1\n",
    "        # run through LSTM network\n",
    "        _, hidden_state = self.lstm(\n",
    "            input_vector,\n",
    "            lengths=effective_encoder_lengths,\n",
    "            enforce_sorted=False,  # passing the lengths directly\n",
    "        )  # second ouput is not needed (hidden state)\n",
    "        return hidden_state\n",
    "\n",
    "    def decode(self, x: Dict[str, torch.Tensor], hidden_state):\n",
    "        # again lag target by one\n",
    "        input_vector = x[\"decoder_cont\"].clone()\n",
    "        input_vector[..., self.target_positions] = torch.roll(\n",
    "            input_vector[..., self.target_positions], shifts=1, dims=1\n",
    "        )\n",
    "        # but this time fill in missing target from encoder_cont at the first time step instead of throwing it away\n",
    "        last_encoder_target = x[\"encoder_cont\"][\n",
    "            torch.arange(x[\"encoder_cont\"].size(0), device=x[\"encoder_cont\"].device),\n",
    "            x[\"encoder_lengths\"] - 1,\n",
    "            self.target_positions.unsqueeze(-1),\n",
    "        ].T\n",
    "        input_vector[:, 0, self.target_positions] = last_encoder_target\n",
    "\n",
    "        if self.training:  # training mode\n",
    "            lstm_output, _ = self.lstm(\n",
    "                input_vector,\n",
    "                hidden_state,\n",
    "                lengths=x[\"decoder_lengths\"],\n",
    "                enforce_sorted=False,\n",
    "            )\n",
    "\n",
    "            # transform into right shape\n",
    "            prediction = self.output_layer(lstm_output)\n",
    "            prediction = self.transform_output(\n",
    "                prediction, target_scale=x[\"target_scale\"]\n",
    "            )\n",
    "\n",
    "            # predictions are not yet rescaled\n",
    "            return prediction\n",
    "\n",
    "        else:  # prediction mode\n",
    "            target_pos = self.target_positions\n",
    "\n",
    "            def decode_one(idx, lagged_targets, hidden_state):\n",
    "                x = input_vector[:, [idx]]\n",
    "                # overwrite at target positions\n",
    "                x[:, 0, target_pos] = lagged_targets[\n",
    "                    -1\n",
    "                ]  # take most recent target (i.e. lag=1)\n",
    "                lstm_output, hidden_state = self.lstm(x, hidden_state)\n",
    "                # transform into right shape\n",
    "                prediction = self.output_layer(lstm_output)[:, 0]  # take first timestep\n",
    "                return prediction, hidden_state\n",
    "\n",
    "            # make predictions which are fed into next step\n",
    "            output = self.decode_autoregressive(\n",
    "                decode_one,\n",
    "                first_target=input_vector[:, 0, target_pos],\n",
    "                first_hidden_state=hidden_state,\n",
    "                target_scale=x[\"target_scale\"],\n",
    "                n_decoder_steps=input_vector.size(1),\n",
    "            )\n",
    "\n",
    "            # predictions are already rescaled\n",
    "            return output\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        hidden_state = self.encode(x)  # encode to hidden state\n",
    "        output = self.decode(x, hidden_state)  # decode leveraging hidden state\n",
    "\n",
    "        return self.to_network_output(prediction=output)\n",
    "\n",
    "\n",
    "model = LSTMModel.from_dataset(dataset, n_layers=2, hidden_size=10)\n",
    "model.summarize(\"full\")\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1c5859a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction shape in training: torch.Size([4, 2, 1])\n",
      "prediction shape in inference: torch.Size([4, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "\n",
    "print(\n",
    "    \"prediction shape in training:\", model(x)[\"prediction\"].size()\n",
    ")  # batch_size x decoder time steps x 1 (1 for one target dimension)\n",
    "model.eval()  # set model into eval mode to use autoregressive prediction\n",
    "print(\n",
    "    \"prediction shape in inference:\", model(x)[\"prediction\"].size()\n",
    ")  # should be the same as in training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99abb92",
   "metadata": {},
   "source": [
    "## Using and defining a custom/non-trivial metric\n",
    "To use a different metric, simply pass it to the model when initializing it (preferably via the from_dataset() method). For example, to use mean absolute error with our FullyConnectedModel from the beginning of this tutorial, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bf89280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hidden_size\":                10\n",
       "\"input_size\":                 5\n",
       "\"learning_rate\":              0.001\n",
       "\"log_gradient_flow\":          False\n",
       "\"log_interval\":               -1\n",
       "\"log_val_interval\":           -1\n",
       "\"logging_metrics\":            ModuleList()\n",
       "\"monotone_constaints\":        {}\n",
       "\"n_hidden_layers\":            2\n",
       "\"optimizer\":                  ranger\n",
       "\"optimizer_params\":           None\n",
       "\"output_size\":                2\n",
       "\"output_transformer\":         GroupNormalizer()\n",
       "\"reduce_on_plateau_min_lr\":   1e-05\n",
       "\"reduce_on_plateau_patience\": 1000\n",
       "\"weight_decay\":               0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_forecasting.metrics import MAE\n",
    "\n",
    "model = FullyConnectedModel.from_dataset(\n",
    "    dataset, hidden_size=10, n_hidden_layers=2, loss=MAE()\n",
    ")\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "262bd23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2, 7])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class FullyConnectedMultiOutputModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        hidden_size: int,\n",
    "        n_hidden_layers: int,\n",
    "        n_outputs: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # input layer\n",
    "        module_list = [nn.Linear(input_size, hidden_size), nn.ReLU()]\n",
    "        # hidden layers\n",
    "        for _ in range(n_hidden_layers):\n",
    "            module_list.extend([nn.Linear(hidden_size, hidden_size), nn.ReLU()])\n",
    "        # output layer\n",
    "        self.n_outputs = n_outputs\n",
    "        module_list.append(\n",
    "            nn.Linear(hidden_size, output_size * n_outputs)\n",
    "        )  # <<<<<<<< modified: replaced output_size with output_size * n_outputs\n",
    "\n",
    "        self.sequential = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x of shape: batch_size x n_timesteps_in\n",
    "        # output of shape batch_size x n_timesteps_out\n",
    "        return self.sequential(x).reshape(\n",
    "            x.size(0), -1, self.n_outputs\n",
    "        )  # <<<<<<<< modified: added reshape\n",
    "\n",
    "\n",
    "# test that network works as intended\n",
    "network = FullyConnectedMultiOutputModule(\n",
    "    input_size=5, output_size=2, hidden_size=10, n_hidden_layers=2, n_outputs=7\n",
    ")\n",
    "network(\n",
    "    torch.rand(20, 5)\n",
    ").shape  # <<<<<<<<<< instead of shape (20, 2), returning additional dimension for quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18c5b9c",
   "metadata": {},
   "source": [
    "### Implement a new metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8224bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.metrics import MultiHorizonMetric\n",
    "\n",
    "\n",
    "class MAE(MultiHorizonMetric):\n",
    "    def loss(self, y_pred, target):\n",
    "        loss = (self.to_prediction(y_pred) - target).abs()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be26fbc",
   "metadata": {},
   "source": [
    "### Model ouptut cannot be readily converted to prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de5c6d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                 | Type                            | Params\n",
      "--------------------------------------------------------------------------\n",
      "0  | loss                 | NormalDistributionLoss          | 0     \n",
      "1  | logging_metrics      | ModuleList                      | 0     \n",
      "2  | network              | FullyConnectedMultiOutputModule | 324   \n",
      "3  | network.sequential   | Sequential                      | 324   \n",
      "4  | network.sequential.0 | Linear                          | 60    \n",
      "5  | network.sequential.1 | ReLU                            | 0     \n",
      "6  | network.sequential.2 | Linear                          | 110   \n",
      "7  | network.sequential.3 | ReLU                            | 0     \n",
      "8  | network.sequential.4 | Linear                          | 110   \n",
      "9  | network.sequential.5 | ReLU                            | 0     \n",
      "10 | network.sequential.6 | Linear                          | 44    \n",
      "--------------------------------------------------------------------------\n",
      "324       Trainable params\n",
      "0         Non-trainable params\n",
      "324       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"hidden_size\":                10\n",
       "\"input_size\":                 5\n",
       "\"learning_rate\":              0.001\n",
       "\"log_gradient_flow\":          False\n",
       "\"log_interval\":               -1\n",
       "\"log_val_interval\":           -1\n",
       "\"logging_metrics\":            ModuleList()\n",
       "\"monotone_constaints\":        {}\n",
       "\"n_hidden_layers\":            2\n",
       "\"optimizer\":                  ranger\n",
       "\"optimizer_params\":           None\n",
       "\"output_size\":                2\n",
       "\"output_transformer\":         GroupNormalizer()\n",
       "\"reduce_on_plateau_min_lr\":   1e-05\n",
       "\"reduce_on_plateau_patience\": 1000\n",
       "\"weight_decay\":               0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "from pytorch_forecasting.metrics import NormalDistributionLoss\n",
    "\n",
    "\n",
    "class FullyConnectedForDistributionLossModel(\n",
    "    BaseModel\n",
    "):  # we inherit the `from_dataset` method\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        output_size: int,\n",
    "        hidden_size: int,\n",
    "        n_hidden_layers: int,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(**kwargs)\n",
    "        self.network = FullyConnectedMultiOutputModule(\n",
    "            input_size=self.hparams.input_size,\n",
    "            output_size=self.hparams.output_size,\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            n_hidden_layers=self.hparams.n_hidden_layers,\n",
    "            n_outputs=2,  # <<<<<<<< we predict two outputs for mean and scale of the normal distribution\n",
    "        )\n",
    "        self.loss = NormalDistributionLoss()\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset: TimeSeriesDataSet, **kwargs):\n",
    "        new_kwargs = {\n",
    "            \"output_size\": dataset.max_prediction_length,\n",
    "            \"input_size\": dataset.max_encoder_length,\n",
    "        }\n",
    "        new_kwargs.update(\n",
    "            kwargs\n",
    "        )  # use to pass real hyperparameters and override defaults set by dataset\n",
    "        # example for dataset validation\n",
    "        assert (\n",
    "            dataset.max_prediction_length == dataset.min_prediction_length\n",
    "        ), \"Decoder only supports a fixed length\"\n",
    "        assert (\n",
    "            dataset.min_encoder_length == dataset.max_encoder_length\n",
    "        ), \"Encoder only supports a fixed length\"\n",
    "        assert (\n",
    "            len(dataset.time_varying_known_categoricals) == 0\n",
    "            and len(dataset.time_varying_known_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_categoricals) == 0\n",
    "            and len(dataset.static_categoricals) == 0\n",
    "            and len(dataset.static_reals) == 0\n",
    "            and len(dataset.time_varying_unknown_reals) == 1\n",
    "            and dataset.time_varying_unknown_reals[0] == dataset.target\n",
    "        ), \"Only covariate should be the target in 'time_varying_unknown_reals'\"\n",
    "\n",
    "        return super().from_dataset(dataset, **new_kwargs)\n",
    "\n",
    "    def forward(\n",
    "        self, x: Dict[str, torch.Tensor], n_samples: int = None\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        network_input = x[\"encoder_cont\"].squeeze(-1)\n",
    "        prediction = self.network(\n",
    "            network_input\n",
    "        )  # shape batch_size x n_decoder_steps x 2\n",
    "        # we need to scale the parameters to real space\n",
    "        prediction = self.transform_output(\n",
    "            prediction=prediction,\n",
    "            target_scale=x[\"target_scale\"],\n",
    "        )\n",
    "        if n_samples is not None:\n",
    "            # sample from distribution\n",
    "            prediction = self.loss.sample(prediction, n_samples)\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)\n",
    "\n",
    "\n",
    "model = FullyConnectedForDistributionLossModel.from_dataset(\n",
    "    dataset, hidden_size=10, n_hidden_layers=2\n",
    ")\n",
    "model.summarize(\"full\")\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ec29a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"decoder_lengths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "761d6e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter predition shape:  torch.Size([4, 2, 2])\n",
      "sample prediction shape:  torch.Size([4, 2, 200])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "\n",
    "print(\"parameter predition shape: \", model(x)[\"prediction\"].size())\n",
    "model.eval()  # set model into eval mode for sampling\n",
    "print(\"sample prediction shape: \", model(x, n_samples=200)[\"prediction\"].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "826e7f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 2, 7])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dataloader, mode=\"quantiles\", mode_kwargs=dict(n_samples=100)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "baccf075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d3668bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.8]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NormalDistributionLoss(quantiles=[0.2, 0.8]).quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b042a",
   "metadata": {},
   "source": [
    "## Adding custom plotting and interpretation\n",
    "### Log often whenever an example prediction vs actuals plot is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5da7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_prediction(\n",
    "    self,\n",
    "    x: Dict[str, torch.Tensor],\n",
    "    out: Dict[str, torch.Tensor],\n",
    "    idx: int,\n",
    "    plot_attention: bool = True,\n",
    "    add_loss_to_title: bool = False,\n",
    "    show_future_observed: bool = True,\n",
    "    ax=None,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot actuals vs prediction and attention\n",
    "\n",
    "    Args:\n",
    "        x (Dict[str, torch.Tensor]): network input\n",
    "        out (Dict[str, torch.Tensor]): network output\n",
    "        idx (int): sample index\n",
    "        plot_attention: if to plot attention on secondary axis\n",
    "        add_loss_to_title: if to add loss to title. Default to False.\n",
    "        show_future_observed: if to show actuals for future. Defaults to True.\n",
    "        ax: matplotlib axes to plot on\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: matplotlib figure\n",
    "    \"\"\"\n",
    "    # plot prediction as normal\n",
    "    fig = super().plot_prediction(\n",
    "        x,\n",
    "        out,\n",
    "        idx=idx,\n",
    "        add_loss_to_title=add_loss_to_title,\n",
    "        show_future_observed=show_future_observed,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    # add attention on secondary axis\n",
    "    if plot_attention:\n",
    "        interpretation = self.interpret_output(out)\n",
    "        ax = fig.axes[0]\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.set_ylabel(\"Attention\")\n",
    "        encoder_length = x[\"encoder_lengths\"][idx]\n",
    "        ax2.plot(\n",
    "            torch.arange(-encoder_length, 0),\n",
    "            interpretation[\"attention\"][idx, :encoder_length].detach().cpu(),\n",
    "            alpha=0.2,\n",
    "            color=\"k\",\n",
    "        )\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc16cf",
   "metadata": {},
   "source": [
    "### Log at the end of an epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5eb80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.utils import detach\n",
    "\n",
    "\n",
    "def create_log(self, x, y, out, batch_idx, **kwargs):\n",
    "    # log standard\n",
    "    log = super().create_log(x, y, out, batch_idx, **kwargs)\n",
    "    # calculate interpretations etc for latter logging\n",
    "    if self.log_interval > 0:\n",
    "        interpretation = self.interpret_output(\n",
    "            detach(out),\n",
    "            reduction=\"sum\",\n",
    "            attention_prediction_horizon=0,  # attention only for first prediction horizon\n",
    "        )\n",
    "        log[\"interpretation\"] = interpretation\n",
    "    return log\n",
    "\n",
    "\n",
    "def epoch_end(self, outputs):\n",
    "    \"\"\"\n",
    "    Run at epoch end for training or validation\n",
    "    \"\"\"\n",
    "    if self.log_interval > 0:\n",
    "        self.log_interpretation(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889c3c3",
   "metadata": {},
   "source": [
    "### Log at the end of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6adc509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_fit_end(self):\n",
    "    \"\"\"\n",
    "    run at the end of training\n",
    "    \"\"\"\n",
    "    if self.log_interval > 0:\n",
    "        for name, emb in self.input_embeddings.items():\n",
    "            labels = self.hparams.embedding_labels[name]\n",
    "            self.logger.experiment.add_embedding(\n",
    "                emb.weight.data.cpu(),\n",
    "                metadata=labels,\n",
    "                tag=name,\n",
    "                global_step=self.global_step,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe7abd",
   "metadata": {},
   "source": [
    "## Minimal testing of models\n",
    "Testing models is essential to quickly detect problems and iterate quickly. Some issues can be only identified after lengthy training but many problems show up after one or two batches. PyTorch Lightning, on which PyTorch Forecasting is built, makes it easy to set up such tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76488041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "/tmp/Python/python-3.9.6/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:530: LightningDeprecationWarning: `trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.fit(train_dataloaders)` instead. HINT: added 's'\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name            | Type                            | Params\n",
      "--------------------------------------------------------------------\n",
      "0 | loss            | NormalDistributionLoss          | 0     \n",
      "1 | logging_metrics | ModuleList                      | 0     \n",
      "2 | network         | FullyConnectedMultiOutputModule | 324   \n",
      "--------------------------------------------------------------------\n",
      "324       Trainable params\n",
      "0         Non-trainable params\n",
      "324       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:00<00:00,  3.73it/s, loss=1.42, v_num=, train_loss_step=1.420]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 2/2 [00:01<00:00,  2.55it/s, loss=1.42, v_num=, train_loss_step=1.420, val_loss=0.857]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:01<00:00,  2.38it/s, loss=1.42, v_num=, train_loss_step=1.420, val_loss=0.857]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "model = FullyConnectedForDistributionLossModel.from_dataset(\n",
    "    dataset, hidden_size=10, n_hidden_layers=2, log_interval=1\n",
    ")\n",
    "trainer = Trainer(fast_dev_run=True)\n",
    "trainer.fit(model, train_dataloader=dataloader, val_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba920437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
