{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, inputDim, hiddenDim, outputDim):\n",
    "        super(Predictor, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=inputDim, hidden_size=hiddenDim, batch_first=True\n",
    "        )\n",
    "        self.output_layer = nn.Linear(hiddenDim, outputDim)\n",
    "\n",
    "    def forward(self, inputs, hidden0=None):\n",
    "        output, (hidden, cell) = self.rnn(inputs, hidden0)\n",
    "        output = self.output_layer(output[:, -1, :])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkDataSet(data_size, data_length=50, freq=60.0, noise=0.00):\n",
    "    \"\"\"\n",
    "    params\\n\n",
    "    data_size : データセットサイズ\\n\n",
    "    data_length : 各データの時系列長\\n\n",
    "    freq : 周波数\\n\n",
    "    noise : ノイズの振幅\\n\n",
    "    returns\\n\n",
    "    train_x : トレーニングデータ（t=1,2,...,size-1の値)\\n\n",
    "    train_t : トレーニングデータのラベル（t=sizeの値）\\n\n",
    "    \"\"\"\n",
    "    train_x = []\n",
    "    train_t = []\n",
    "\n",
    "    for offset in range(data_size):\n",
    "        train_x.append(\n",
    "            [\n",
    "                [\n",
    "                    math.sin(2 * math.pi * (offset + i) / freq)\n",
    "                    + np.random.normal(loc=0.0, scale=noise)\n",
    "                ]\n",
    "                for i in range(data_length)\n",
    "            ]\n",
    "        )\n",
    "        train_t.append([math.sin(2 * math.pi * (offset + data_length) / freq)])\n",
    "\n",
    "    return train_x, train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す。\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    batch_t = []\n",
    "\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - 1)\n",
    "        batch_x.append(train_x[idx])\n",
    "        batch_t.append(train_t[idx])\n",
    "\n",
    "    return torch.tensor(batch_x), torch.tensor(batch_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    training_size = 10000\n",
    "    test_size = 1000\n",
    "    epochs_num = 100\n",
    "    hidden_size = 5\n",
    "    batch_size = 100\n",
    "\n",
    "    train_x, train_t = mkDataSet(training_size)\n",
    "    test_x, test_t = mkDataSet(test_size)\n",
    "\n",
    "    model = Predictor(1, hidden_size, 1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(epochs_num):\n",
    "        # training\n",
    "        running_loss = 0.0\n",
    "        training_accuracy = 0.0\n",
    "        for i in range(int(training_size / batch_size)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            data, label = mkRandomBatch(train_x, train_t, batch_size)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.data.item()\n",
    "            training_accuracy += np.sum(\n",
    "                np.abs((output.data - label.data).numpy()) < 0.1\n",
    "            )\n",
    "\n",
    "        # test\n",
    "        test_accuracy = 0.0\n",
    "        for i in range(int(test_size / batch_size)):\n",
    "            offset = i * batch_size\n",
    "            data, label = (\n",
    "                torch.tensor(test_x[offset : offset + batch_size]),\n",
    "                torch.tensor(test_t[offset : offset + batch_size]),\n",
    "            )\n",
    "            output = model(data, None)\n",
    "\n",
    "            test_accuracy += np.sum(\n",
    "                np.abs((output.data - label.data).numpy()) < 0.1\n",
    "            )\n",
    "\n",
    "        training_accuracy /= training_size\n",
    "        test_accuracy /= test_size\n",
    "\n",
    "        print(\n",
    "            \"%d loss: %.3f, training_accuracy: %.5f, test_accuracy: %.5f\"\n",
    "            % (epoch + 1, running_loss, training_accuracy, test_accuracy)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss: 50.462, training_accuracy: 0.06750, test_accuracy: 0.06700\n",
      "2 loss: 39.416, training_accuracy: 0.06840, test_accuracy: 0.08300\n",
      "3 loss: 25.802, training_accuracy: 0.09060, test_accuracy: 0.11800\n",
      "4 loss: 12.317, training_accuracy: 0.12940, test_accuracy: 0.13600\n",
      "5 loss: 5.584, training_accuracy: 0.13050, test_accuracy: 0.13600\n",
      "6 loss: 3.781, training_accuracy: 0.14560, test_accuracy: 0.15300\n",
      "7 loss: 3.274, training_accuracy: 0.16010, test_accuracy: 0.18600\n",
      "8 loss: 2.950, training_accuracy: 0.16830, test_accuracy: 0.15200\n",
      "9 loss: 2.671, training_accuracy: 0.16330, test_accuracy: 0.16800\n",
      "10 loss: 2.531, training_accuracy: 0.16820, test_accuracy: 0.16800\n",
      "11 loss: 2.370, training_accuracy: 0.18180, test_accuracy: 0.21900\n",
      "12 loss: 2.176, training_accuracy: 0.21080, test_accuracy: 0.21800\n",
      "13 loss: 2.098, training_accuracy: 0.24100, test_accuracy: 0.25200\n",
      "14 loss: 1.996, training_accuracy: 0.24600, test_accuracy: 0.25200\n",
      "15 loss: 1.873, training_accuracy: 0.29190, test_accuracy: 0.31600\n",
      "16 loss: 1.818, training_accuracy: 0.33430, test_accuracy: 0.33400\n",
      "17 loss: 1.712, training_accuracy: 0.37160, test_accuracy: 0.38300\n",
      "18 loss: 1.684, training_accuracy: 0.37030, test_accuracy: 0.38300\n",
      "19 loss: 1.600, training_accuracy: 0.39650, test_accuracy: 0.41500\n",
      "20 loss: 1.521, training_accuracy: 0.42830, test_accuracy: 0.43200\n",
      "21 loss: 1.473, training_accuracy: 0.45080, test_accuracy: 0.45000\n",
      "22 loss: 1.445, training_accuracy: 0.45650, test_accuracy: 0.46600\n",
      "23 loss: 1.366, training_accuracy: 0.51090, test_accuracy: 0.54600\n",
      "24 loss: 1.327, training_accuracy: 0.55360, test_accuracy: 0.56500\n",
      "25 loss: 1.254, training_accuracy: 0.59230, test_accuracy: 0.61400\n",
      "26 loss: 1.239, training_accuracy: 0.60440, test_accuracy: 0.58000\n",
      "27 loss: 1.216, training_accuracy: 0.61900, test_accuracy: 0.63100\n",
      "28 loss: 1.164, training_accuracy: 0.63040, test_accuracy: 0.63100\n",
      "29 loss: 1.113, training_accuracy: 0.65070, test_accuracy: 0.64700\n",
      "30 loss: 1.098, training_accuracy: 0.65830, test_accuracy: 0.64700\n",
      "31 loss: 1.051, training_accuracy: 0.66100, test_accuracy: 0.66400\n",
      "32 loss: 1.019, training_accuracy: 0.65840, test_accuracy: 0.66400\n",
      "33 loss: 0.985, training_accuracy: 0.66840, test_accuracy: 0.68100\n",
      "34 loss: 0.950, training_accuracy: 0.68280, test_accuracy: 0.68100\n",
      "35 loss: 0.924, training_accuracy: 0.68590, test_accuracy: 0.69700\n",
      "36 loss: 0.875, training_accuracy: 0.70590, test_accuracy: 0.69700\n",
      "37 loss: 0.850, training_accuracy: 0.70710, test_accuracy: 0.69700\n",
      "38 loss: 0.825, training_accuracy: 0.69950, test_accuracy: 0.69700\n",
      "39 loss: 0.787, training_accuracy: 0.71280, test_accuracy: 0.71400\n",
      "40 loss: 0.767, training_accuracy: 0.72340, test_accuracy: 0.73000\n",
      "41 loss: 0.725, training_accuracy: 0.73850, test_accuracy: 0.73000\n",
      "42 loss: 0.691, training_accuracy: 0.75020, test_accuracy: 0.74700\n",
      "43 loss: 0.666, training_accuracy: 0.76210, test_accuracy: 0.76400\n",
      "44 loss: 0.642, training_accuracy: 0.77370, test_accuracy: 0.78000\n",
      "45 loss: 0.612, training_accuracy: 0.79040, test_accuracy: 0.78000\n",
      "46 loss: 0.582, training_accuracy: 0.79750, test_accuracy: 0.79700\n",
      "47 loss: 0.554, training_accuracy: 0.81080, test_accuracy: 0.81400\n",
      "48 loss: 0.530, training_accuracy: 0.83090, test_accuracy: 0.83000\n",
      "49 loss: 0.503, training_accuracy: 0.83520, test_accuracy: 0.83000\n",
      "50 loss: 0.472, training_accuracy: 0.85030, test_accuracy: 0.86400\n",
      "51 loss: 0.448, training_accuracy: 0.88520, test_accuracy: 0.88100\n",
      "52 loss: 0.423, training_accuracy: 0.90530, test_accuracy: 0.93200\n",
      "53 loss: 0.400, training_accuracy: 0.93860, test_accuracy: 0.93200\n",
      "54 loss: 0.376, training_accuracy: 0.95920, test_accuracy: 0.96600\n",
      "55 loss: 0.356, training_accuracy: 0.97330, test_accuracy: 1.00000\n",
      "56 loss: 0.332, training_accuracy: 0.99690, test_accuracy: 1.00000\n",
      "57 loss: 0.310, training_accuracy: 0.99740, test_accuracy: 1.00000\n",
      "58 loss: 0.294, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "59 loss: 0.275, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "60 loss: 0.258, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "61 loss: 0.243, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "62 loss: 0.226, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "63 loss: 0.212, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "64 loss: 0.201, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "65 loss: 0.189, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "66 loss: 0.181, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "67 loss: 0.170, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "68 loss: 0.165, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "69 loss: 0.158, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "70 loss: 0.148, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "71 loss: 0.142, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "72 loss: 0.137, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "73 loss: 0.132, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "74 loss: 0.131, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "75 loss: 0.127, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "76 loss: 0.121, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "77 loss: 0.120, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "78 loss: 0.117, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "79 loss: 0.112, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "80 loss: 0.110, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "81 loss: 0.111, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "82 loss: 0.105, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "83 loss: 0.102, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "84 loss: 0.103, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "85 loss: 0.102, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "86 loss: 0.099, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "87 loss: 0.096, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "88 loss: 0.094, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "89 loss: 0.093, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "90 loss: 0.092, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "91 loss: 0.092, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "92 loss: 0.091, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "93 loss: 0.088, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "94 loss: 0.087, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "95 loss: 0.085, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "96 loss: 0.085, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "97 loss: 0.085, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "98 loss: 0.084, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "99 loss: 0.080, training_accuracy: 1.00000, test_accuracy: 1.00000\n",
      "100 loss: 0.080, training_accuracy: 1.00000, test_accuracy: 1.00000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
